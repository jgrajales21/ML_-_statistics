{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ed317",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = (\"dog\", \"cat\", \"rat\", \"ate\", \"the\", \"cat\")\n",
    "d2 = (\"dog\", \"chair\", \"table\", \"and\", \"the\", \"chair\")\n",
    "d3 = (\"dog\", \"cat\", \"chair\", \"chased\", \"the\", \"cat\",\"bug\")\n",
    "docs = [d1,d2,d3]\n",
    "#Get the vocabulary\n",
    "vocab = ['chair', 'chased', 'cat', 'dog', 'ate', 'table', 'the', 'rat', 'and',\"bug\"]\n",
    "doc_vectors = list()\n",
    "for doc in docs:\n",
    "    d_vector = list()\n",
    "    for word in doc:\n",
    "        ind = vocab.index(word)\n",
    "        d_vector.append(ind)\n",
    "    doc_vectors.append(d_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43487ddf",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size:xx-large\">Dirichlet parameters</span>\n",
    "<li>Alpha is the parameter for the prior topic distribution within documents</li>\n",
    "<li>Beta is the parameter for the prior topic distribution within documents</li>\n",
    "<li>num_passes is the number of times the algorithm will update the topic assignments</li>\n",
    "<li>num_topics is the number of topics</li>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperparameters in LDA\n",
    "# alpha,beta  are the dirichlet distribution parameter\n",
    "\n",
    "alpha = 0.2\n",
    "beta = 0.001\n",
    "num_passes = 100\n",
    "num_topics = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a75ac",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size:xx-large\">Data parameters</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data parameters\n",
    "v = len(vocab) #size of the vocabulary\n",
    "num_docs = len(doc_vectors) #number of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ec0b4",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size:xx-large\">Initialize vectors</span>\n",
    "<li>word_topic_counts will keep track of the number of occurrences of a word in a topic</li>\n",
    "<li>doc_topics_counts will keep track of the number of occurrences of a topic in a document</li>\n",
    "<li>topics_vector keeps the assignment of topics to word-document combinations</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a115e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize counting vectors\n",
    "word_topic_counts = np.zeros((num_topics,v)) #Count the \n",
    "topics_vector = [np.zeros(len(l)) for l in doc_vectors]  #Word-Document topics assignment \n",
    "doc_topics_counts= np.zeros((num_docs,num_topics))\n",
    "doc_topics_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae68820e",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size:xx-large\">random topic assignment</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random assignment of topics in topics_vector\n",
    "np.random.seed(42)\n",
    "for i in range(len(doc_vectors)):\n",
    "    topics_vector[i] = np.random.randint(low=0,high=num_topics,size=len(doc_vectors[i]))\n",
    "topics_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3494f0aa",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size:xx-large\">get word_topic_counts</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b199dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get word topic counts\n",
    "#Note that this will be a 2x10 matrix num_topics x vocab-length\n",
    "for j in range(len(topics_vector)):\n",
    "    doc = topics_vector[j]\n",
    "    for i in range(len(doc)):\n",
    "        w_t = topics_vector[j][i]\n",
    "        word_topic_counts[int(w_t),doc_vectors[j][i]]+=1\n",
    "        \n",
    "        \n",
    "word_topic_counts   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876adce",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size:xx-large\">get document topic counts</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6899f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get document-topic probabilities\n",
    "for j in range(len(topics_vector)):\n",
    "    doc = topics_vector[j]\n",
    "    for i in range(len(doc)):\n",
    "        topic = topics_vector[j][i]\n",
    "        doc_topics_counts[j,topic] +=1\n",
    "doc_topics_counts \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14262382",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size:xx-large\">Do the LDA</span>\n",
    "<li>Bit tricky but the basic idea is to update topic assignments using the probabilities</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The LDA\n",
    "#For each word doc combo, get the initial topic assignment and update it\n",
    "for p in range(num_passes): \n",
    "    for i in range(num_docs):\n",
    "        for j in range(len(doc_vectors[i])):\n",
    "            assigned_topic = int(topics_vector[i][j])\n",
    "            vocab_id = doc_vectors[i][j] \n",
    "            \n",
    "            #While examining this word, remove it from our current topic counts\n",
    "            #In other words, we won't include this in our probabilities\n",
    "            doc_topics_counts[i][assigned_topic] -= 1\n",
    "            word_topic_counts[assigned_topic][vocab_id] -= 1\n",
    "\n",
    "            #Calculate probabilities\n",
    "            prob_term1 = np.array([doc_topics_counts[i][col] for col in range(num_topics)]) + alpha\n",
    "            prob_term1 = prob_term1/(sum(doc_topics_counts[i]) + num_topics*alpha)\n",
    "            prob_term2 = np.array([word_topic_counts[row][vocab_id] for row in range(num_topics)]) + beta\n",
    "            prob_term2 = prob_term2/(np.sum(word_topic_counts, axis = 1) + v*beta)\n",
    "            \n",
    "            probs = prob_term1 * prob_term2\n",
    "            probs = probs/sum(probs)\n",
    " \n",
    "           #Update topic assignment using the probabilities found above (this is a probabilistic update)\n",
    "            \n",
    "            update_topic_assign = np.random.choice(num_topics,1,list(probs))\n",
    "            topics_vector[i][j] = update_topic_assign\n",
    "            \n",
    "            #Update the counts (we had removed this from the counts, we need to add it back)\n",
    "            doc_topics_counts[i][assigned_topic] += 1\n",
    "            word_topic_counts[assigned_topic][vocab_id] +=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d16ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta is the posterior (computed) probability matrix of document topic \n",
    "theta = (doc_topics_counts+alpha)\n",
    "theta_row_sum = np.sum(theta, axis = 1)\n",
    "theta = theta/theta_row_sum.reshape((num_docs,1))\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85f71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPUQr+Ch7ZBfAWtgI0u2pJX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"OYMl0B05E--T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Neural network packages\n","* MLPClassifier and MLPRegressor in sklearn (home assignment)\n","* Tensorflow and Keras (open source libraries developed by Google)\n","* PyTorch (open source libraries developed by Meta/Facebook)"],"metadata":{"id":"LNG2YgogFCPw"}},{"cell_type":"markdown","source":["<h1>Tensorflow</h1>\n","<li>end to end opensource tool for deep learning</li>\n","<li>A <span style=\"color:blue\">tensor</span> is an n-dimensional mathematical object</li>\n","<li>n=0 => scalar</li>\n","<li>n=1 => vector</li>\n","<li>n=2 => matrix</li>\n","<li>n>2 => tensor</li>\n","<li>tensorflow was built to provide support for numerical computation in high dimensional mathematical objects</li>"],"metadata":{"id":"iyr7boo1yy96"}},{"cell_type":"code","source":["import tensorflow as tf\n","tf.__version__"],"metadata":{"id":"X6fA272VzB1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kaUvcbkg1c2i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h2>Keras</h2>\n","<li>Keras is an open source \"human friendly\" tensorflow wrapper</li>\n","<li>tensorflow provides the math, keras provides an ML interface to tensorflow</li>\n","<li>We'll implement our \"non-linear\" model example in keras/tf</li>"],"metadata":{"id":"7K4lib_l1e42"}},{"cell_type":"code","source":["import numpy as np\n","import keras\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","training_data = np.array([[0,0,1],\n","            [0,1,1],\n","            [1,0,1],\n","            [1,1,1],\n","             [1,1,0],\n","             [0,1,0],\n","             [1,0,0],\n","             [1,0,0]],\"float32\")\n","\n","y = np.array([[0],[1],[1],[1],[1],[0],[0],[0]],\"float32\")"],"metadata":{"id":"FY1Awf6yy49J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h3>Our network</h3>\n","<li>A <b>sequential</b> network (inputs will flow sequentially toward outputs)</li>\n","<li>3 nodes in the input layer (<b>input_dim = 3</b>)</li>\n","<li>A <b>dense</b> network is a fully connected network</li>\n","<li>We'll add a hidden layer of 16 nodes (connected to the 3 input nodes)</li>\n","<li>And an output layer of 1 node</li>"],"metadata":{"id":"6sGQvNsS3575"}},{"cell_type":"code","source":["model = Sequential(name=\"My_Example\")\n","model.add(Dense(16, input_dim=3, activation='relu',name=\"layer_1\"))\n","model.add(Dense(1, activation='sigmoid',name=\"output_layer\"))"],"metadata":{"id":"uIs8TUOT1Wm7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h2>ReLu: Rectified Linear Unit</h2>\n","<li>The sigmoid function, while easy to use, has a drawback</li>\n","<ul>\n","<li>large values snap to 1.0 and -1.0 quickly</li>\n","<li>the function is sensitive around the midpoint (0.5) but not much elsewhere</li>\n","<li>this makes it harder for the algorithm to adapt, and this is especially a problem with large datasets and many layered (deep) networks</li>\n","<li><b>vanishing gradient problem</b>: as the error is backpropagated through many layers, it decreases and the derivative becomes smaller and smaller so the weights barely change. (information is not well utilized)</li>\n","</ul>\n","\n","<li>Relu is a popular activation function</li>\n","\n","<li>The function:\n","<p>\n","$ f_{x} = \\left\\{\\begin{array}{ll}\n","0 & if \\ x\\leq 0 \\\\\n","x & if \\ x \\gt 0\n","\\end{array}\\right.$\n","\n","The function can be rewritten as:\n","\n","$ f_{x} = max(0,x) $\n","\n","linear above 0 and non-linear below 0 (negative values become 0). Linear functions are more generalizable and don't suffer from the vanishing gradient problem\n","\n","\n"],"metadata":{"id":"XDqJ-tuAdFay"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"ZOzVKlmi_8eR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<li><b>Optimizer</b> refers to the algorithm that tweaks weights during backpropogation</li>\n","<li>Typically, stochastic gradient descent is used</li>\n","<li><b>adam</b> extends stochastic gradient descent </li>\n","<ul>\n","<li>faster convergence</li>\n","<li>adaptive learning rates</li>\n","<li>See: <a href=\"https://www.geeksforgeeks.org/intuition-of-adam-optimizer/\">https://www.geeksforgeeks.org/intuition-of-adam-optimizer/</a></li>\n","</ul>\n","<li><b>binary_accuracy</b> is a keras metric that converts predictions (floats between 0 and 1) into 0 or 1 binary values using a threshold of 0.5</li>"],"metadata":{"id":"kjDrsLDXzltO"}},{"cell_type":"code","source":["model.compile(loss='mean_squared_error',\n","              optimizer='adam',\n","              metrics=['binary_accuracy'])"],"metadata":{"id":"TFe42MKX24pr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(training_data, y, epochs=200,verbose=0)"],"metadata":{"id":"AumwjWlb3fVS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict(training_data).round() #round returns 0 or 1 rather than the predicted float value\n","#y = np.array([[0],[1],[1],[1],[1],[0],[0],[0]],\"float32\")"],"metadata":{"id":"xQegDzMu3i6a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_data"],"metadata":{"id":"Rbr62-JF52BT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = np.array([[1, 1, 1],\n","       [0, 1, 1],\n","       [1, 0, 0],\n","       [0, 0, 1]],\"float32\")\n","model.predict(test_data).round()"],"metadata":{"id":"i5ucxGWZ7_XO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict(test_data)"],"metadata":{"id":"Wp5h5r-2BAim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OgirpCiK-loJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h1>Classifying handwritten digits</h1>\n","<li>Let's use a neural net to build a handwritten digits predictor</li>"],"metadata":{"id":"R5cnm1gjIuKs"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_openml\n","mnist = fetch_openml('mnist_784')\n","mnist.keys()"],"metadata":{"id":"bbkDhdFhgQ8O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<li>Let's take a look at the data by drawing the digits</li>"],"metadata":{"id":"g2d574j8nVqb"}},{"cell_type":"code","source":["digit_number = 37833\n","for line in mnist.data.to_numpy()[digit_number].reshape(28,28):\n","    for num in line:\n","        if num > 0:\n","            print('*', end = ' ')\n","        else:\n","            print(' ', end = ' ')\n","    print('')\n","print(\"Actual value: \",mnist.target.to_numpy()[digit_number])\n"],"metadata":{"id":"zUu8TSaqMF98"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h3>Training and testing data</h3>\n","<li>The data is in a tuple ((training data, training labels), (testing data, testing labels)) </li>\n","<li>extract training (60,000) and testing (10,000) data</li>\n","<li>normalize the independent variables</li>\n","<li>one hot encode the target values using <b>to_categorical</b> (keras one hot encoding function)</li>"],"metadata":{"id":"3Cpg2v6ip84p"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from tensorflow.keras.utils import to_categorical\n","tf.random.set_seed(7)\n","from sklearn.model_selection import train_test_split\n","\n","mnist = keras.datasets.mnist\n","(train_iv, train_dv), (test_iv,\n","                               test_dv) = mnist.load_data()\n","\n","# Standardize the data.\n","mean = np.mean(train_iv)\n","stddev = np.std(train_iv)\n","train_iv = (train_iv - mean) / stddev\n","test_iv = (test_iv - mean) / stddev\n","\n","# One-hot encode labels.\n","train_dv = to_categorical(train_dv, num_classes=10)\n","test_dv = to_categorical(test_dv, num_classes=10)"],"metadata":{"id":"rVK3M1WSMssJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dv"],"metadata":{"id":"nDEE5FvltfWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"88a9NIPgtCA-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h2>Creating the neural network</h2>\n","<li>We'll create a Sequential network as in our earlier example</li>\n","<li>"],"metadata":{"id":"6xW1Z1JdvtEv"}},{"cell_type":"code","source":["# Object used to initialize weights.\n","initializer = keras.initializers.RandomUniform(\n","    minval=-0.1, maxval=0.1)\n","\n","# Create a Sequential model.\n","\n","model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=(28, 28)), #Converts each 28x28 matrix into a 784 vector\n","    keras.layers.Dense(25, activation='tanh', #the tanh activation function (values from -1 to 1 unlike sigmoid 0 to 1)\n","                       kernel_initializer=initializer,\n","                       bias_initializer='zeros'), #a bias input vector for regularization\n","    keras.layers.Dense(10, activation='relu', #output layer - 10 values, relu activation (fires/doesn't fire)\n","                       kernel_initializer=initializer,\n","                       bias_initializer='zeros')])"],"metadata":{"id":"VX813iCnv5ZT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["initializer"],"metadata":{"id":"C2VqZKAM7Vw5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h3>Training Parameters</h3>\n","<li><b>EPOCH</b>: Number of training passes</li>\n","<li><b>Batch Size</b>: Number of cases used to update the network (batch size = 1 means that each case is passed through the network and weights are updated. 60000 in each epoch!</li>\n","<li><b>Initializer</b>: An object that picks values from a uniform distribution between -0.1 and 0.1</li>\n"],"metadata":{"id":"bPYDGmr6ZnOx"}},{"cell_type":"code","source":["\n","\n","EPOCHS = 20\n","BATCH_SIZE = 2"],"metadata":{"id":"ixsg3Gv-zvzl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_dv)"],"metadata":{"id":"D3fXiLER9U6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SGD optimizer with learning rate of 0.01\n","# MSE loss function\n","\n","opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n","\n","model.compile(loss='mean_squared_error', optimizer = opt,\n","              metrics =['accuracy'])\n","\n","# Train the model for 5 epochs (result for 20 epochs is below)\n","# Shuffle (randomize) order.\n","# Update weights after each example (batch_size=1).\n","history = model.fit(train_iv, train_dv,\n","                    validation_data=(test_iv, test_dv),\n","                    epochs=EPOCHS, batch_size=BATCH_SIZE,\n","                    verbose=2, shuffle=True)"],"metadata":{"id":"EEZjNqOSv-mD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<li><b>loss</b>: mean square error on the training set</li>\n","<li><b>accuracy</b>: accuracy on the training set</li>\n","<li><b>val_loss</b>: mean square error on the test set</li>\n","<li><b>val_accuracy</b>: accuracy on the test set</li>\n","<li>Progression of stats across 20 epochs:</li>\n","<pre>\n","Epoch 1/20\n","60000/60000 - 72s - loss: 0.0549 - accuracy: 0.6740 - val_loss: 0.0284 - val_accuracy: 0.8826 - 72s/epoch - 1ms/step\n","Epoch 2/20\n","60000/60000 - 73s - loss: 0.0226 - accuracy: 0.8900 - val_loss: 0.0182 - val_accuracy: 0.9063 - 73s/epoch - 1ms/step\n","Epoch 3/20\n","60000/60000 - 72s - loss: 0.0173 - accuracy: 0.9062 - val_loss: 0.0158 - val_accuracy: 0.9153 - 72s/epoch - 1ms/step\n","Epoch 4/20\n","60000/60000 - 73s - loss: 0.0153 - accuracy: 0.9149 - val_loss: 0.0145 - val_accuracy: 0.9192 - 73s/epoch - 1ms/step\n","Epoch 5/20\n","60000/60000 - 73s - loss: 0.0142 - accuracy: 0.9196 - val_loss: 0.0136 - val_accuracy: 0.9235 - 73s/epoch - 1ms/step\n","Epoch 6/20\n","60000/60000 - 72s - loss: 0.0134 - accuracy: 0.9235 - val_loss: 0.0131 - val_accuracy: 0.9264 - 72s/epoch - 1ms/step\n","Epoch 7/20\n","60000/60000 - 73s - loss: 0.0128 - accuracy: 0.9269 - val_loss: 0.0129 - val_accuracy: 0.9241 - 73s/epoch - 1ms/step\n","Epoch 8/20\n","60000/60000 - 72s - loss: 0.0124 - accuracy: 0.9292 - val_loss: 0.0125 - val_accuracy: 0.9283 - 72s/epoch - 1ms/step\n","Epoch 9/20\n","60000/60000 - 73s - loss: 0.0119 - accuracy: 0.9312 - val_loss: 0.0122 - val_accuracy: 0.9300 - 73s/epoch - 1ms/step\n","Epoch 10/20\n","60000/60000 - 74s - loss: 0.0116 - accuracy: 0.9333 - val_loss: 0.0122 - val_accuracy: 0.9298 - 74s/epoch - 1ms/step\n","Epoch 11/20\n","60000/60000 - 72s - loss: 0.0112 - accuracy: 0.9354 - val_loss: 0.0118 - val_accuracy: 0.9314 - 72s/epoch - 1ms/step\n","Epoch 12/20\n","60000/60000 - 73s - loss: 0.0110 - accuracy: 0.9378 - val_loss: 0.0118 - val_accuracy: 0.9297 - 73s/epoch - 1ms/step\n","Epoch 13/20\n","60000/60000 - 73s - loss: 0.0107 - accuracy: 0.9394 - val_loss: 0.0114 - val_accuracy: 0.9339 - 73s/epoch - 1ms/step\n","Epoch 14/20\n","60000/60000 - 73s - loss: 0.0104 - accuracy: 0.9407 - val_loss: 0.0114 - val_accuracy: 0.9324 - 73s/epoch - 1ms/step\n","Epoch 15/20\n","60000/60000 - 73s - loss: 0.0102 - accuracy: 0.9419 - val_loss: 0.0111 - val_accuracy: 0.9345 - 73s/epoch - 1ms/step\n","Epoch 16/20\n","60000/60000 - 83s - loss: 0.0100 - accuracy: 0.9430 - val_loss: 0.0109 - val_accuracy: 0.9357 - 83s/epoch - 1ms/step\n","Epoch 17/20\n","60000/60000 - 73s - loss: 0.0098 - accuracy: 0.9441 - val_loss: 0.0110 - val_accuracy: 0.9346 - 73s/epoch - 1ms/step\n","Epoch 18/20\n","60000/60000 - 73s - loss: 0.0097 - accuracy: 0.9446 - val_loss: 0.0110 - val_accuracy: 0.9342 - 73s/epoch - 1ms/step\n","Epoch 19/20\n","60000/60000 - 72s - loss: 0.0095 - accuracy: 0.9457 - val_loss: 0.0108 - val_accuracy: 0.9362 - 72s/epoch - 1ms/step\n","Epoch 20/20\n","60000/60000 - 73s - loss: 0.0094 - accuracy: 0.9466 - val_loss: 0.0107 - val_accuracy: 0.9359 - 73s/epoch - 1ms/step\n","</pre>"],"metadata":{"id":"3uXpPLRf9wZA"}},{"cell_type":"code","source":[],"metadata":{"id":"D9BP7YT_jnkr"},"execution_count":null,"outputs":[]}]}
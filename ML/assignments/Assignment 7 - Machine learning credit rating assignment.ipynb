{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Credit rating assignment</h1>\n",
    "<p></p>\n",
    "In this assignment, we'll work our way through a simple ML exercise. Machine learning is an iterative process that starts with feature engineering (making the features ready for ML), works it way through various models and hyperparameter tuning exercises, until we find a model that seems to work well for us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">The problem: Rating creditworthiness of loan applicants</h3>\n",
    "\n",
    "When banks issue loans to individuals, they have two goals that conflict with each other:\n",
    "<ol>\n",
    "    <li>Give as many loans as possible (fees, interest, all add to revenue)</li>\n",
    "    <li>Try not to give loans to individuals who won't pay it back (lose money on the loan, collection costs, etc.)</li>\n",
    "</ol>\n",
    "    \n",
    "<li>A typical machine learning program in this space tries to find a suitable tradeoff between finding many good loans and not calling a bad loan good</li>\n",
    "\n",
    "<li>In this assignment, we'll try to build a \"good\" model that finds a good tradeoff between these two objectives</li>\n",
    "\n",
    "<li>In machine learning terms, the proportion of times we get our guess right (i.e., we call a bad loan a bad loan and a good loan a good loan divided by the total number of cases) is called <span style=\"color:blue\">accuracy</span></li>\n",
    "\n",
    "<li>The proportion of actual good loans that we identify as good loans is known as <span style=\"color:blue\">recall</span></li>\n",
    "\n",
    "<li>The probability that if a loan is called good it actually is good is called <span style=\"color:blue\">precision</span></li>\n",
    "\n",
    "<li>The precision recall tradeoff is measured through a score called <span style=\"color:blue\">f1 score</span></li>\n",
    "\n",
    "<li>An important part of running an ML model is trying to figure out \"which metric is right for you\"</li>\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "<ol>\n",
    "    <li>We'll try the SGD classifier, tune hyperparameters using grid search, and examine the results</li>\n",
    "    <li>then, set up the data for a random forest classifier, run a grid search, and examine the results</li>\n",
    "        <li>finally, run a couple of gradient booster models</li>\n",
    "\n",
    "    <li>draw precision recall curves and roc curves for the two classifiers and compare the results</li>\n",
    "    <li>note that grid search is a computing intensive activity. I've simplified the search to a few options but even those can take a long while (less than 15 minutes on my laptop but could be a couple of hours if you have an older machine)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">The models</h3>\n",
    "<p></p>\n",
    "<li><b>Model 1 SGD Classifier</b>: Vanilla version with max_iter set to 1000</li>\n",
    "<li><b>Model 2 SGD Classifier round 2</b>: SGD Classifier with positive cases assigned a higher weight. One issue with our data is that positive cases are vastly outnumbered by negative cases (in other words, a model that says all cases are negative will have a pretty good accuracy). By overweighting positive cases in our model, we increase the efficacy of the model in finding an actual good solution</li>\n",
    "<li><b>Model 3 SGD Classifier round 3</b>: Best SGD Classifier model after grid search</li>\n",
    "<li><b>Model 4 Random Forest Classifier round 1</b>: Random Forest Classifier with base parameters (see below)</li>\n",
    "<li><b>Model 5 Random Forest Classifier round 2</b>: Best model from grid search</li>\n",
    "<li><b>Model 6 Gradient Booster Classfier</b></li>\n",
    "<li><b>Model 7 Gradient Booster Classifier (2nd model)</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each model, collect model metrics in the following dataframe results_df. After each model run, replace the 0.0 with the appropriate metric value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision  recall  f1_score  AUC   AP\n",
       "Model                                                 \n",
       "1           0.0        0.0     0.0       0.0  0.0  0.0\n",
       "2           0.0        0.0     0.0       0.0  0.0  0.0\n",
       "3           0.0        0.0     0.0       0.0  0.0  0.0\n",
       "4           0.0        0.0     0.0       0.0  0.0  0.0\n",
       "5           0.0        0.0     0.0       0.0  0.0  0.0\n",
       "6           0.0        0.0     0.0       0.0  0.0  0.0\n",
       "7           0.0        0.0     0.0       0.0  0.0  0.0"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "results_df = pd.DataFrame(np.zeros(shape=(7,6)))\n",
    "results_df.index=[1,2,3,4,5,6,7]\n",
    "results_df.columns = [\"accuracy\",\"precision\",\"recall\",\"f1_score\",\"AUC\",\"AP\"]\n",
    "results_df.index.rename(\"Model\",inplace=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">The data</h3>\n",
    "<p></p>\n",
    "<li>A curated extract from the popular Lending club loan data. The data is in the file loan_data_small.csv</li>\n",
    "<li>The dataset contains information about loan applications. Very basic information about the applicant and the status of the loan</li>\n",
    "<li>The goal of the ML exercise is to build a model that uses information about the loan to predict whether a loan is a \"good\" one (i.e., it will be paid back) or a \"bad\" one (the money is unrecoverable)</li>\n",
    "<li>Note that we're only using a fraction of the data. If you're interested, I can share the curated extract on a larger fraction which gives better results (but can crash your machine!)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-size:xx-large\">Data preparation and feature engineering</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Build a binary target</h3>\n",
    "\n",
    "<li>For the purposes of this analysis, drop rows that contain any NaN values</li>\n",
    "<li><b>Target</b>: For the classifier, classify any loans that have a loan_status value of \"Charged Off\",\"Default\", or \"Does not meet the credit policy. Status:Charged Off\" as a bad loan and give these loans a target value of 1 (we're predicting bad loans)</li>\n",
    "<li><b>Input features</b>: create the input feature dataframe (i.e., drop any columns that are not an independent variable). The input variables we're interested in are \"int_rate\", \"grade\", \"home_ownership\",\"annual_income\", \"loan_amt\", and \"purpose\"</li>\n",
    "<p></p>\n",
    "<li>The data should look like:</li>\n",
    "<pre>\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 565167 entries, 0 to 565166\n",
    "Data columns (total 7 columns):\n",
    " #   Column          Non-Null Count   Dtype  \n",
    "---  ------          --------------   -----  \n",
    " 0   Unnamed: 0.1    565167 non-null  int64  \n",
    " 1   int_rate        565167 non-null  float64\n",
    " 2   grade           565167 non-null  object \n",
    " 3   home_ownership  565167 non-null  object \n",
    " 4   annual_inc      565167 non-null  float64\n",
    " 5   loan_amnt       565167 non-null  int64  \n",
    " 6   purpose         565167 non-null  object \n",
    "dtypes: float64(2), int64(2), object(3)\n",
    "memory usage: 30.2+ MB\n",
    "Out[108]:\n",
    "0         False\n",
    "1          True\n",
    "2         False\n",
    "3         False\n",
    "4          True\n",
    "          ...  \n",
    "565162    False\n",
    "565163    False\n",
    "565164    False\n",
    "565165     True\n",
    "565166    False\n",
    "Name: loan_status, Length: 565167, dtype: bool\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 565167 entries, 0 to 565166\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   int_rate        565167 non-null  float64\n",
      " 1   grade           565167 non-null  object \n",
      " 2   home_ownership  565167 non-null  object \n",
      " 3   annual_inc      565167 non-null  float64\n",
      " 4   loan_amnt       565167 non-null  int64  \n",
      " 5   purpose         565167 non-null  object \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 25.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65231"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"loan_data_small.csv\")\n",
    "\n",
    "#Drop rows with NaN values\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "#Prepare the y (target) variable\n",
    "#The target variable should be 1 if loan_status is \"Charged Off\",\"Default\", or \"Does not meet the credit policy. Status:Charged Off\"\n",
    "#And 0 otherwise\n",
    "#(Hint: Create a boolean mask series)\n",
    "\n",
    "y = df.apply(lambda x: \n",
    "             1 if x['loan_status'] == 'Charged Off' else \n",
    "             1 if x['loan_status'] == 'Default' else\n",
    "             1 if x['loan_status'] == 'Does not meet the credit policy. Status:Charged Off' else\n",
    "            0\n",
    "            ,axis=1)\n",
    "\n",
    "#remove unwanted input features \"Unnamed: 0\" and \"loan_status\"\n",
    "df.drop(columns=['Unnamed: 0','loan_status','Unnamed: 0.1'], inplace=True)\n",
    "\n",
    "#Examine the df and the target\n",
    "df.info()\n",
    "\n",
    "y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Label Encoding</h3>\n",
    "<li>Since we're using regression as our underlying algorithm, all values need to be numerical. ML Models generally deal with numerical data</li>\n",
    "<li>But, <span style=\"color:blue\">grade</span>, <span style=\"color:blue\">purpose</span>, and <span style=\"color:blue\">home_ownership</span> are not</li>\n",
    "</li>\n",
    "<li>sklearn's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\">LabelEncoder</a> assigns numerical values to categorical data</li>\n",
    "<li>LabelEncoder replaces each categorical string value with an integer - 0, 1, 2, ...</li>\n",
    "<li>After label encoding, df.info() should return:</li>\n",
    "<pre>\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 565167 entries, 0 to 565166\n",
    "Data columns (total 7 columns):\n",
    " #   Column          Non-Null Count   Dtype  \n",
    "---  ------          --------------   -----  \n",
    " 0   Unnamed: 0.1    565167 non-null  int64  \n",
    " 1   int_rate        565167 non-null  float64\n",
    " 2   grade           565167 non-null  int64  \n",
    " 3   home_ownership  565167 non-null  int64  \n",
    " 4   annual_inc      565167 non-null  float64\n",
    " 5   loan_amnt       565167 non-null  int64  \n",
    " 6   purpose         565167 non-null  int64  \n",
    "dtypes: float64(2), int64(5)\n",
    "memory usage: 30.2 MB\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(939678, 1530033, 1650049)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace grade, purpose, and home_ownership by label encoded versions\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# transform the grade\n",
    "le_grader = LabelEncoder()\n",
    "le_grader.fit(df['grade'])\n",
    "new_grade_col = le_grader.transform(df['grade'])\n",
    "\n",
    "# transform the purpose \n",
    "le_purpose = LabelEncoder()\n",
    "le_purpose.fit(df['purpose'])\n",
    "new_purpose_col = le_purpose.transform(df['purpose'])\n",
    "\n",
    "# transform the home_ownership\n",
    "le_ho = LabelEncoder()\n",
    "le_ho.fit(df['home_ownership'])\n",
    "new_home_ownership_col = le_ho.transform(df['home_ownership'])\n",
    "\n",
    "# now we assing these columns to the dataframe \n",
    "df['grade'] = new_grade_col\n",
    "df['purpose'] = new_purpose_col\n",
    "df['home_ownership'] = new_home_ownership_col\n",
    "\n",
    "df['grade'].sum(), df['purpose'].sum(), df['home_ownership'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 565167 entries, 0 to 565166\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   int_rate        565167 non-null  float64\n",
      " 1   grade           565167 non-null  int64  \n",
      " 2   home_ownership  565167 non-null  int64  \n",
      " 3   annual_inc      565167 non-null  float64\n",
      " 4   loan_amnt       565167 non-null  int64  \n",
      " 5   purpose         565167 non-null  int64  \n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 25.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">One-hot encoding</h3>\n",
    "\n",
    "<p></p>\n",
    "<li>In regression, the assumption is that values associated with a feature are ordered</li>\n",
    "<li>But, this is not necessarily so for the label encoded categorical values</li>\n",
    "<li>The way to deal with this in regression is to create dummy variables, one for each category, that take the value 1 if the category is present in the row and 0 otherwise</li>\n",
    "<li>In ML, a procedure known as <a href=\"https://en.wikipedia.org/wiki/One-hot\">one-hot encoding</a> is used to do this conversion</li>\n",
    "<li>One hot encoding is the process of converting a single column of categorical (integer) data with k categories into k-1 columns of 0 or 1 values</li>\n",
    "<li>for example, the array with three possible categories [1,2,3,2,1] will be converted into the matrix:</li>\n",
    "\n",
    "$$\\begin{bmatrix} 0 & 0 \\\\ 1 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$$\n",
    "\n",
    "<li>1's are replaced by (0, 0); 2's by (1, 0); and 3's by (0, 1). Note that category 1 is implicitly coded</li>\n",
    "<li><b>Documentation</b>: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Scaling</h3>\n",
    "\n",
    "<p></p>\n",
    "<li>Non-categorical independent variables need to be scaled so that they follow the same underlying distribution</li>\n",
    "<li>We will normalize them so that the mean is 0 and standard deviation is 1 using sklearn's StandardScaler feature transformer</li>\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>All feature transformations can be encapsulated in the sklearn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html\">make_column_transformer</a> object</li>\n",
    "<li>Use <span style=\"color:blue\">make_column_transformer</span> to encapsulate both the one-hot coding as well as standard scaling. Note that the one-hot encoded columns are not scaled!</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565167, 26)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "#Make a column transformer object that scales (using StandardScaler) the two non-categorical columns\n",
    "# and one hot encodes (using OneHotEncoder) the three categorical columns\n",
    "# Using make_column_transformer \n",
    "preprocess = make_column_transformer(\n",
    "    (StandardScaler(),['int_rate', 'annual_inc'], ),\n",
    "    (OneHotEncoder(categories=\"auto\",drop=\"first\"),['grade', 'home_ownership','purpose'], )\n",
    ")\n",
    "\n",
    "#Generate the independent variable df\n",
    "X = preprocess.fit_transform(df).toarray()\n",
    "X.shape\n",
    "#Should return (565167, 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Train/Test split</h3>\n",
    "\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html</a></li>\n",
    "<li>split the data into 70% training and 30% testing</li>\n",
    "<li>make sure the x and y datasets are aligned</li>\n",
    "<li>use random_state=42 to get the same split as in my code </li>\n",
    "<li>x and y training data shapes: (395616, 26) (395616,)</li>\n",
    "<li>x and y testing data shapes: (169551, 26) (169551,)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395616, 26) (395616,)\n",
      "(169551, 26) (169551,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nShould return:\\n(395616, 26) (395616,)\\n(169551, 26) (169551,)\\n'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Get x_train, x_test, y_train, y_test\n",
    "\n",
    "# the percent of the data that we want for training\n",
    "train_size = .7 \n",
    "\n",
    "# use 30% of the data for testing an 70% for training \n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=1-train_size,random_state=42)\n",
    "\n",
    "#And check the shape\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)\n",
    "\n",
    "\"\"\"\n",
    "Should return:\n",
    "(395616, 26) (395616,)\n",
    "(169551, 26) (169551,)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27542382, -0.54678873,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.81078196,  1.05693436,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.20043776,  0.4221273 ,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.79059571, -0.3930986 ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.18940226, -0.85299293,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.09698959, -0.0656718 ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\">The models</h1>\n",
    "<li>For each model, do the following</li>\n",
    "<ol>\n",
    "    <li>Fit a classifier to the training data</li>\n",
    "    <li>calculate the metrics</li>\n",
    "    <ul>\n",
    "        <li>training accuracy</li>\n",
    "        <li>testing accuracy</li>\n",
    "        <li>precision on test dataset</li>\n",
    "        <li>recall on test dataset</li>\n",
    "        <li>f1 score on test dataset</li>\n",
    "        <li>area under the curve on test dataset</li>\n",
    "        <li>average precision on the test dataset</li>\n",
    "    </ul>\n",
    "    <li>Write up a brief (pointwise) interpretation of the results\n",
    "</ol>\n",
    "<li>Chart the various metrics</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-size:xx-large\">Build Model 1</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Build the model on the training data set</h3>\n",
    "\n",
    "<li>set random_state to 42 (if you want to get the same results that I got) and max_iter to 1000</li>\n",
    "<li>set the loss function to \"log_loss\" (\"log\" if using sklearn 1.0.x or on colab)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8846634109843889\n",
      "0.8843828700508991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou should get:\\n0.8846634109843889\\n0.8843828700508991\\n'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model_1 = SGDClassifier(random_state=42,loss='log_loss',max_iter=1000)\n",
    "model_1.fit(x_train,y_train) \n",
    "\n",
    "print(model_1.score(x_train,y_train))\n",
    "print(model_1.score(x_test,y_test))\n",
    "\"\"\"\n",
    "You should get:\n",
    "0.8846634109843889\n",
    "0.8843828700508991\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 style=\"color:green;\">Model 1 metrics</h3>\n",
    "<li>Report the following on the <b>test</b> data:</li>\n",
    "<ul>\n",
    "<li>the confusion matrix</li>\n",
    "<li>the accuracy, precision, recall, f1-score, AUC, and AP </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[149948      1]\n",
      " [ 19602      0]]\n",
      "Training accuracy:  0.8846634109843889\n",
      "Testing  accuracy:  0.8843828700508991\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F1-Score:  0.0\n",
      "AUC:  0.6929621775583544\n",
      "Average Precision:  0.2277691812634675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nYou should see:\\n\\nConfusion Matrix: \\n [[149948      1]\\n [ 19602      0]]\\nTraining accuracy:  0.8846634109843889\\nTesting  accuracy:  0.8843828700508991\\nPrecision:  0.0\\nRecall:  0.0\\nF1-Score:  0.0\\nAUC:  0.692962177388246\\nAverage Precision:  0.11561123201868465\\n'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score\n",
    "from sklearn.metrics import average_precision_score,roc_auc_score\n",
    "\n",
    "# run on train \n",
    "y_train_pred = model_1.predict(x_train)\n",
    "cfm = confusion_matrix(y_train,y_train_pred)\n",
    "accuracy_training = accuracy_score(y_train,y_train_pred)\n",
    "\n",
    "# run on test data \n",
    "y_test_pred = model_1.predict(x_test)\n",
    "cfm = confusion_matrix(y_test,y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "accuracy_testing = accuracy_score(y_test,y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc = roc_auc_score(y_test, model_1.decision_function(x_test))\n",
    "ap = average_precision_score(y_test, model_1.decision_function(x_test))\n",
    "\n",
    "print(\"Confusion Matrix: \\n\",cfm)\n",
    "print(\"Training accuracy: \",accuracy_training)\n",
    "print(\"Testing  accuracy: \",accuracy_testing)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1-Score: \",f1)\n",
    "print(\"AUC: \",auc)\n",
    "print(\"Average Precision: \",ap)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "You should see:\n",
    "\n",
    "Confusion Matrix: \n",
    " [[149948      1]\n",
    " [ 19602      0]]\n",
    "Training accuracy:  0.8846634109843889\n",
    "Testing  accuracy:  0.8843828700508991\n",
    "Precision:  0.0\n",
    "Recall:  0.0\n",
    "F1-Score:  0.0\n",
    "AUC:  0.692962177388246\n",
    "Average Precision:  0.11561123201868465\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Interpret the results</h3>\n",
    "<li>In a few bullet points, write your interpreation of the results. Why are we seeing what we are seeing? Is it useful? Why is the AUC not 0.5?</li>\n",
    "\n",
    "<h4>Interpretation</h4>\n",
    "<li> Overall it seems as if the model is performing well as the accuracy is very similar between the testing and training datasets. This implies that the model is not overfitted. </li>\n",
    "<li> We note that the precision is very low, this tells us that we are assigning a large number of false positives. In other words a large number of more 'good loan individuals' were identified, more than the true number of 'good loan individuals'. </li>\n",
    "<li> Interestingly, we also observe a low recall. This tells us that there is a large number of false negatives. In other words a large number of 'bad loan individuals' were identifeied, more than the true number of 'bad loan individuals'. </li>\n",
    "<li> An f1 score tells us how close our model is to perfect precision and recall. We remind ourselves that a good model has a large f1 score (close to 1). Considering ours are pretty low this confirms the fact that our precision and accuracy are low. </li>\n",
    "<li> We remind ourselves that an AUC of 0.5 implies that the model is a random classifier. At the moment our SGD classififer is marginally \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Update results_df</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.227769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision  recall  f1_score       AUC        AP\n",
       "Model                                                           \n",
       "1      0.884383        0.0     0.0       0.0  0.692962  0.227769\n",
       "2      0.000000        0.0     0.0       0.0  0.000000  0.000000\n",
       "3      0.000000        0.0     0.0       0.0  0.000000  0.000000\n",
       "4      0.000000        0.0     0.0       0.0  0.000000  0.000000\n",
       "5      0.000000        0.0     0.0       0.0  0.000000  0.000000\n",
       "6      0.000000        0.0     0.0       0.0  0.000000  0.000000\n",
       "7      0.000000        0.0     0.0       0.0  0.000000  0.000000"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[1] = [accuracy_testing,precision,recall,f1,auc,ap]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-size:xx-large\">Build Model 2</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<li>sklearn's ML models can be given a <span style=\"color:blue\">class_weight</span> parameter</li>\n",
    "<li>weights can be given explicitly or implicitly</li>\n",
    "<li>note that by increasing the weight of the true cases, our model is more likely to find true positives</li>\n",
    "<li>and by decreasing the weight of the true cases, our model is more likely to find true negatives</li>\n",
    "<li>In Model 2, increase the weight of positives by a factor of 9 to balance the positives and negatives</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">Build model 2 and report metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5627401318450215\n",
      "0.5625033175858591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model_2 = SGDClassifier(random_state=42,\n",
    "                        loss='log_loss',\n",
    "                        max_iter=1000,\n",
    "                        class_weight={0:1, 1:9})\n",
    "model_2.fit(x_train,y_train) #change if you used different variable names\n",
    "\n",
    "print(model_2.score(x_train,y_train))\n",
    "print(model_2.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Update results_df</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[81037 68912]\n",
      " [ 5266 14336]]\n",
      "Training accuracy:  0.5627401318450215\n",
      "Testing  accuracy:  0.5625033175858591\n",
      "Precision:  0.17220834134153373\n",
      "Recall:  0.7313539434751556\n",
      "F1-Score:  0.27877491492464757\n",
      "AUC:  0.6940091593866806\n",
      "Average Precision:  0.22986705851283923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.227769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.562503</td>\n",
       "      <td>0.172208</td>\n",
       "      <td>0.731354</td>\n",
       "      <td>0.278775</td>\n",
       "      <td>0.694009</td>\n",
       "      <td>0.229867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.630896</td>\n",
       "      <td>0.183822</td>\n",
       "      <td>0.637384</td>\n",
       "      <td>0.285349</td>\n",
       "      <td>0.689325</td>\n",
       "      <td>0.225067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.801033</td>\n",
       "      <td>0.248407</td>\n",
       "      <td>0.355933</td>\n",
       "      <td>0.292604</td>\n",
       "      <td>0.694597</td>\n",
       "      <td>0.228761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.756876</td>\n",
       "      <td>0.239756</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>0.325777</td>\n",
       "      <td>0.727998</td>\n",
       "      <td>0.255029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.802520</td>\n",
       "      <td>0.268904</td>\n",
       "      <td>0.411999</td>\n",
       "      <td>0.325416</td>\n",
       "      <td>0.748437</td>\n",
       "      <td>0.259061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.756563</td>\n",
       "      <td>0.245389</td>\n",
       "      <td>0.532803</td>\n",
       "      <td>0.336020</td>\n",
       "      <td>0.747998</td>\n",
       "      <td>0.259703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall  f1_score       AUC        AP\n",
       "Model                                                             \n",
       "1      0.884383   0.000000  0.000000  0.000000  0.692962  0.227769\n",
       "2      0.562503   0.172208  0.731354  0.278775  0.694009  0.229867\n",
       "3      0.630896   0.183822  0.637384  0.285349  0.689325  0.225067\n",
       "4      0.801033   0.248407  0.355933  0.292604  0.694597  0.228761\n",
       "5      0.756876   0.239756  0.508060  0.325777  0.727998  0.255029\n",
       "6      0.802520   0.268904  0.411999  0.325416  0.748437  0.259061\n",
       "7      0.756563   0.245389  0.532803  0.336020  0.747998  0.259703"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run on train \n",
    "y_train_pred = model_2.predict(x_train)\n",
    "cfm = confusion_matrix(y_train,y_train_pred)\n",
    "accuracy_training = accuracy_score(y_train,y_train_pred)\n",
    "\n",
    "# run on test data \n",
    "y_test_pred = model_2.predict(x_test)\n",
    "cfm = confusion_matrix(y_test,y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "accuracy_testing = accuracy_score(y_test,y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc = roc_auc_score(y_test, model_2.decision_function(x_test))\n",
    "ap = average_precision_score(y_test, model_2.decision_function(x_test))\n",
    "\n",
    "print(\"Confusion Matrix: \\n\",cfm)\n",
    "print(\"Training accuracy: \",accuracy_training)\n",
    "print(\"Testing  accuracy: \",accuracy_testing)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1-Score: \",f1)\n",
    "print(\"AUC: \",auc)\n",
    "print(\"Average Precision: \",ap)\n",
    "\n",
    "results_df.loc[2] = [accuracy_testing,precision,recall,f1,auc,ap]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Interpret the results</h3>\n",
    "\n",
    "\n",
    "<h4>Interpretation</h4>\n",
    "<li> Our model seems to continue not be overfitted b/c the train and test model have similar accuracy performance. </li>\n",
    "<li> The increase in recall was anticipated beacuse we are weighing positives more we anticpaite increasing the number of positive assignmnets, hence decreasing false negatives and increasing recall overall. </li>\n",
    "<li> Overall the model is doing better with precision and recall, as indicated by the higher f1. </li>\n",
    "<li> Average precision is roughly the same to model 1. </li>\n",
    "<li> Overall we have a higher number of false positives and a lower number of false negatives in comparison to model 1. </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-size:xx-large\">Build Model 3</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Tune hyperparameters using grid search</h3>\n",
    "<li><span style=\"color:blue\">parameters</span> versus <span style=\"color:blue\">hyperparameters</span></li>\n",
    "<ul>\n",
    "    <li><span style=\"color:blue\">parameters</span>: the parameters that are necessary for the model to make predictions. For example, the coefficients of the linear equation estimated by the SGD classifier are parameters of the model. Parameters are estimated by the algorithm and from the data</li>\n",
    "    <li><span style=\"color:blue\">hyperparameters</span>: parameters that are external to the model and cannot be estimated from the data. For example, in an SGD classifier, parameters like the loss function, the regularization parameter, stopping rules, etc. are hyper parameters</li>\n",
    "    </ul>\n",
    "<li>In ML, hyperparameters are often set intuitively and then <span style=\"color:red\">tuned</span> using a grid search</li>\n",
    "<li>In a grid search, various combinations of hyperparameters are tried and <span style=\"color:blue\">k-fold cross validation</span> is used to test the efficacy of the parameter combination</li>\n",
    "<li>the best combination is then selected as a candidate model</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">The <span style=\"color:blue\">scoring</span> parameter</h3>\n",
    "<li>since our data is imbalaced, we should look for the model with the best f1 score (precision/recall tradeoff)</li>\n",
    "<li>set the scoring parameter for GridSearchCV so that it maximizes the f1 score</li>\n",
    "<li>Though we should be using a much wider range of parameters, I've reduced them so that it runs fairly quickly</li>\n",
    "<li>This takes about 30 seconds on my machine. Could take longer on your machine</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6311928738979212\n",
      "0.6308957186923109\n",
      "CPU times: user 2.62 s, sys: 828 ms, total: 3.45 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#Set up the hyperparameter options in param_grid\n",
    "param_grid = GridSearchCV(\n",
    "    estimator = SGDClassifier(),\n",
    "    param_grid = {\n",
    "                    'random_state': [42],\n",
    "                    'loss': ['log_loss'],\n",
    "                    'max_iter': [500,1000,2000], \n",
    "                    'class_weight': [{0:1,1:5},'balanced']\n",
    "                 },\n",
    "    scoring = 'f1',\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "#Do the search\n",
    "param_grid.fit(x_train,y_train)\n",
    "model_3 = SGDClassifier(**param_grid.best_params_)\n",
    "model_3.fit(x_train,y_train)\n",
    "\n",
    "print(model_3.score(x_train,y_train))\n",
    "print(model_3.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Get the best model parameters</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[94475 55474]\n",
      " [ 7108 12494]]\n",
      "Training accuracy:  0.6311928738979212\n",
      "Testing  accuracy:  0.6308957186923109\n",
      "Precision:  0.18382179849340866\n",
      "Recall:  0.6373839404142434\n",
      "F1-Score:  0.28534886376612995\n",
      "AUC:  0.6893247295550745\n",
      "Average Precision:  0.22506688846181813\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.227769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.562503</td>\n",
       "      <td>0.172208</td>\n",
       "      <td>0.731354</td>\n",
       "      <td>0.278775</td>\n",
       "      <td>0.694009</td>\n",
       "      <td>0.229867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.630896</td>\n",
       "      <td>0.183822</td>\n",
       "      <td>0.637384</td>\n",
       "      <td>0.285349</td>\n",
       "      <td>0.689325</td>\n",
       "      <td>0.225067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.801033</td>\n",
       "      <td>0.248407</td>\n",
       "      <td>0.355933</td>\n",
       "      <td>0.292604</td>\n",
       "      <td>0.694597</td>\n",
       "      <td>0.228761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.756876</td>\n",
       "      <td>0.239756</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>0.325777</td>\n",
       "      <td>0.727998</td>\n",
       "      <td>0.255029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.802520</td>\n",
       "      <td>0.268904</td>\n",
       "      <td>0.411999</td>\n",
       "      <td>0.325416</td>\n",
       "      <td>0.748437</td>\n",
       "      <td>0.259061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.756563</td>\n",
       "      <td>0.245389</td>\n",
       "      <td>0.532803</td>\n",
       "      <td>0.336020</td>\n",
       "      <td>0.747998</td>\n",
       "      <td>0.259703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall  f1_score       AUC        AP\n",
       "Model                                                             \n",
       "1      0.884383   0.000000  0.000000  0.000000  0.692962  0.227769\n",
       "2      0.562503   0.172208  0.731354  0.278775  0.694009  0.229867\n",
       "3      0.630896   0.183822  0.637384  0.285349  0.689325  0.225067\n",
       "4      0.801033   0.248407  0.355933  0.292604  0.694597  0.228761\n",
       "5      0.756876   0.239756  0.508060  0.325777  0.727998  0.255029\n",
       "6      0.802520   0.268904  0.411999  0.325416  0.748437  0.259061\n",
       "7      0.756563   0.245389  0.532803  0.336020  0.747998  0.259703"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run on train \n",
    "y_train_pred = model_3.predict(x_train)\n",
    "cfm = confusion_matrix(y_train,y_train_pred)\n",
    "accuracy_training = accuracy_score(y_train,y_train_pred)\n",
    "\n",
    "# run on test data \n",
    "y_test_pred = model_3.predict(x_test)\n",
    "cfm = confusion_matrix(y_test,y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "accuracy_testing = accuracy_score(y_test,y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc = roc_auc_score(y_test, model_3.decision_function(x_test))\n",
    "ap = average_precision_score(y_test, model_3.decision_function(x_test))\n",
    "\n",
    "print(\"Confusion Matrix: \\n\",cfm)\n",
    "print(\"Training accuracy: \",accuracy_training)\n",
    "print(\"Testing  accuracy: \",accuracy_testing)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1-Score: \",f1)\n",
    "print(\"AUC: \",auc)\n",
    "print(\"Average Precision: \",ap)\n",
    "\n",
    "results_df.loc[3] = [accuracy_testing,precision,recall,f1,auc,ap]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Interpret the results</h3>\n",
    "\n",
    "\n",
    "<h4>Interpretation</h4>\n",
    "<li> Overall we've achieved our goal of improving the f1 score (i.e we are, amrginally closer, to perfect precision and recall in comparison to th eprevious models). </li>\n",
    "<li> our model seems to not be overfitted. This model is not much better or worse in comparison to previous models as indicated by the AUC. We observe an increase in precision but a decrease in recall in comaprion to model 2. This tradeoff is expected. This tells us we are identifying more false negatives (good loans called bad) and less false positives (bad loans called good). </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-size:xx-large\">Build Model 4</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Random Forest Classifier</h3>\n",
    "<li>We need to improve recall and precision so perhaps a non-linear classifier will help</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Build, fit, and report metrics</h3>\n",
    "\n",
    "<li>Run this with the following parameters (these are our base parameters)</li>\n",
    "<li>random_state=42,n_estimators=30,max_depth=6,min_samples_leaf=2000,min_samples_split=4000,class_weight={1:5}</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={1: 5}, max_depth=6, min_samples_leaf=500,\n",
       "                       min_samples_split=4000, n_estimators=30,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={1: 5}, max_depth=6, min_samples_leaf=500,\n",
       "                       min_samples_split=4000, n_estimators=30,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={1: 5}, max_depth=6, min_samples_leaf=500,\n",
       "                       min_samples_split=4000, n_estimators=30,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_4 = RandomForestClassifier(random_state=42,n_estimators=30,max_depth=6,min_samples_leaf=500,min_samples_split=4000,class_weight={1:5})\n",
    "model_4.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[128839  21110]\n",
      " [ 12625   6977]]\n",
      "Training accuracy:  0.8021414705168648\n",
      "Testing  accuracy:  0.8010333174089213\n",
      "Precision:  0.24840673621248263\n",
      "Recall:  0.35593306805428016\n",
      "F1-Score:  0.29260416448237536\n",
      "AUC:  0.6945967053414696\n",
      "Average Precision:  0.22876096340572005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.227769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.884389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692871</td>\n",
       "      <td>0.227346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.630896</td>\n",
       "      <td>0.183822</td>\n",
       "      <td>0.637384</td>\n",
       "      <td>0.285349</td>\n",
       "      <td>0.689325</td>\n",
       "      <td>0.225067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.801033</td>\n",
       "      <td>0.248407</td>\n",
       "      <td>0.355933</td>\n",
       "      <td>0.292604</td>\n",
       "      <td>0.694597</td>\n",
       "      <td>0.228761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall  f1_score       AUC        AP\n",
       "Model                                                             \n",
       "1      0.884383   0.000000  0.000000  0.000000  0.692962  0.227769\n",
       "2      0.884389   0.000000  0.000000  0.000000  0.692871  0.227346\n",
       "3      0.630896   0.183822  0.637384  0.285349  0.689325  0.225067\n",
       "4      0.801033   0.248407  0.355933  0.292604  0.694597  0.228761\n",
       "5      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "6      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "7      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run on train \n",
    "y_train_pred = model_4.predict(x_train)\n",
    "cfm = confusion_matrix(y_train,y_train_pred)\n",
    "accuracy_training = accuracy_score(y_train,y_train_pred)\n",
    "\n",
    "# run on test data \n",
    "y_test_pred = model_4.predict(x_test)\n",
    "cfm = confusion_matrix(y_test,y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "accuracy_testing = accuracy_score(y_test,y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc = roc_auc_score(y_test, model_4.predict_proba(x_test)[:,1])\n",
    "ap = average_precision_score(y_test, model_4.predict_proba(x_test)[:,1])\n",
    "\n",
    "print(\"Confusion Matrix: \\n\",cfm)\n",
    "print(\"Training accuracy: \",accuracy_training)\n",
    "print(\"Testing  accuracy: \",accuracy_testing)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1-Score: \",f1)\n",
    "print(\"AUC: \",auc)\n",
    "print(\"Average Precision: \",ap)\n",
    "\n",
    "results_df.loc[4] = [accuracy_testing,precision,recall,f1,auc,ap]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Interpreting model 4 results</h3>\n",
    "<p></p>\n",
    "\n",
    "<h4>Interpretation</h4>\n",
    "<li> Train and test predicitons imply no overfitting. Precision increased using RF in comparison to SGD, i.e we are identifying less false postivies. As a result of RF identifying less false positives our recall also goes down (a result of the precision recall tradeoff). f1 increased implying we are marginally closer to perfect precision and recall.  </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-size:xx-large\">Build Model 5</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Random Forest Grid Search</h3>\n",
    "<p></p>\n",
    "\n",
    "\n",
    "<li>Run the best model</li>\n",
    "<li>Note that this will take a while, perhaps even a couple of hours (25 minutes on my laptop). Let it run. Get some coffee or whatever beverage you like. Then come back in a while to check out the results!</li>\n",
    "<li>If you want to speed it up, remove the 500 option from n_estimators (n_estimators is the number of trees generated and is the single most expensive part of the grid search)</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 37s, sys: 1.92 s, total: 2min 39s\n",
      "Wall time: 11min 30s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{1: 4}, {1: 6}],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20], &#x27;min_samples_split&#x27;: [200],\n",
       "                         &#x27;n_estimators&#x27;: [800]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{1: 4}, {1: 6}],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20], &#x27;min_samples_split&#x27;: [200],\n",
       "                         &#x27;n_estimators&#x27;: [800]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{1: 4}, {1: 6}],\n",
       "                         'min_samples_leaf': [20], 'min_samples_split': [200],\n",
       "                         'n_estimators': [800]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import average_precision_score,make_scorer\n",
    "parameters = {\n",
    "     'n_estimators':[800], #the number of trees\n",
    "     'min_samples_split': [200],\n",
    "    'class_weight': [{1:4},{1:6}],\n",
    "     'min_samples_leaf': [20] #\n",
    "}\n",
    "model_5 = GridSearchCV(RandomForestClassifier(random_state=42),parameters,cv=5,n_jobs=-1,\n",
    "                      scoring='f1')\n",
    "model_5.fit(x_train, np.ravel(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Get the best model parameters</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Run the best model and get metrics</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[118370  31579]\n",
      " [  9643   9959]]\n",
      "Training accuracy:  0.7678809754913856\n",
      "Testing  accuracy:  0.7568755123827049\n",
      "Precision:  0.2397563676633444\n",
      "Recall:  0.508060401999796\n",
      "F1-Score:  0.3257769054628721\n",
      "AUC:  0.7279977050851167\n",
      "Average Precision:  0.25502883958113276\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.227769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.884389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692871</td>\n",
       "      <td>0.227346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.630896</td>\n",
       "      <td>0.183822</td>\n",
       "      <td>0.637384</td>\n",
       "      <td>0.285349</td>\n",
       "      <td>0.689325</td>\n",
       "      <td>0.225067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.801033</td>\n",
       "      <td>0.248407</td>\n",
       "      <td>0.355933</td>\n",
       "      <td>0.292604</td>\n",
       "      <td>0.694597</td>\n",
       "      <td>0.228761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.756876</td>\n",
       "      <td>0.239756</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>0.325777</td>\n",
       "      <td>0.727998</td>\n",
       "      <td>0.255029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall  f1_score       AUC        AP\n",
       "Model                                                             \n",
       "1      0.884383   0.000000  0.000000  0.000000  0.692962  0.227769\n",
       "2      0.884389   0.000000  0.000000  0.000000  0.692871  0.227346\n",
       "3      0.630896   0.183822  0.637384  0.285349  0.689325  0.225067\n",
       "4      0.801033   0.248407  0.355933  0.292604  0.694597  0.228761\n",
       "5      0.756876   0.239756  0.508060  0.325777  0.727998  0.255029\n",
       "6      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "7      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run on train \n",
    "y_train_pred = model_5.predict(x_train)\n",
    "cfm = confusion_matrix(y_train,y_train_pred)\n",
    "accuracy_training = accuracy_score(y_train,y_train_pred)\n",
    "\n",
    "# run on test data \n",
    "y_test_pred = model_5.predict(x_test)\n",
    "cfm = confusion_matrix(y_test,y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "accuracy_testing = accuracy_score(y_test,y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc = roc_auc_score(y_test, model_5.predict_proba(x_test)[:,1])\n",
    "ap = average_precision_score(y_test, model_5.predict_proba(x_test)[:,1])\n",
    "\n",
    "print(\"Confusion Matrix: \\n\",cfm)\n",
    "print(\"Training accuracy: \",accuracy_training)\n",
    "print(\"Testing  accuracy: \",accuracy_testing)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1-Score: \",f1)\n",
    "print(\"AUC: \",auc)\n",
    "print(\"Average Precision: \",ap)\n",
    "\n",
    "results_df.loc[5] = [accuracy_testing,precision,recall,f1,auc,ap]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Interpreting model 5 results</h3>\n",
    "\n",
    "<p>\n",
    "    </p>\n",
    "<h4>Interpretation</h4>\n",
    "<li>Our model is not overfitted. Our precision barely changes as a result of hyperparameter tuning -- perhaps there exists another set of hyperparameters that can optimize for this. Our recall has improved in comparison to the previous RF model though (i.e we are calling less good loan candidates bad, we decreased false negative). Our f1 score is better than model 4 -- we are closer, though still far, from perfect precision and recall. Considerable jump in AUC and AP in combination with f1 score implies this is the best model so far. </li> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-size:xx-large\">Build Model 6</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Gradient Boosting Classifier</li>\n",
    "<li>Grid search on GBC can take several days so let's just skip to the best models (I ran a 2-day reduced version)!</li>\n",
    "<li>Sklearn's gradient boosting classifier uses a sample weight vector to correct for imbalances in the data</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=8, min_samples_leaf=100,\n",
       "                           min_samples_split=100, n_estimators=400,\n",
       "                           subsample=0.6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" checked><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=8, min_samples_leaf=100,\n",
       "                           min_samples_split=100, n_estimators=400,\n",
       "                           subsample=0.6)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(max_depth=8, min_samples_leaf=100,\n",
       "                           min_samples_split=100, n_estimators=400,\n",
       "                           subsample=0.6)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#sample_weight is a vector that indicates the weight of each \n",
    "#case in the training sample\n",
    "#If you're interested, try values from 1 to 10 instead of 4\n",
    "sample_weight = np.array([4 if i == 1 else 1 for i in y_train])\n",
    "\n",
    "\n",
    "model_6 = GradientBoostingClassifier(min_samples_split=100,\n",
    "                                     max_depth=8,\n",
    "                                 min_samples_leaf=100,\n",
    "                                 n_estimators=400,\n",
    "                                 subsample=0.6)\n",
    "\n",
    "\n",
    "model_6.fit(x_train,y_train,sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[127992  21957]\n",
      " [ 11526   8076]]\n",
      "Training accuracy:  0.8176539877052496\n",
      "Testing  accuracy:  0.8025195958738078\n",
      "Precision:  0.2689042053740885\n",
      "Recall:  0.41199877563513926\n",
      "F1-Score:  0.32541553339377455\n",
      "AUC:  0.7484373291143047\n",
      "Average Precision:  0.25906126022378706\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.227769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.884389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692871</td>\n",
       "      <td>0.227346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.630896</td>\n",
       "      <td>0.183822</td>\n",
       "      <td>0.637384</td>\n",
       "      <td>0.285349</td>\n",
       "      <td>0.689325</td>\n",
       "      <td>0.225067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.801033</td>\n",
       "      <td>0.248407</td>\n",
       "      <td>0.355933</td>\n",
       "      <td>0.292604</td>\n",
       "      <td>0.694597</td>\n",
       "      <td>0.228761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.756876</td>\n",
       "      <td>0.239756</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>0.325777</td>\n",
       "      <td>0.727998</td>\n",
       "      <td>0.255029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.802520</td>\n",
       "      <td>0.268904</td>\n",
       "      <td>0.411999</td>\n",
       "      <td>0.325416</td>\n",
       "      <td>0.748437</td>\n",
       "      <td>0.259061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall  f1_score       AUC        AP\n",
       "Model                                                             \n",
       "1      0.884383   0.000000  0.000000  0.000000  0.692962  0.227769\n",
       "2      0.884389   0.000000  0.000000  0.000000  0.692871  0.227346\n",
       "3      0.630896   0.183822  0.637384  0.285349  0.689325  0.225067\n",
       "4      0.801033   0.248407  0.355933  0.292604  0.694597  0.228761\n",
       "5      0.756876   0.239756  0.508060  0.325777  0.727998  0.255029\n",
       "6      0.802520   0.268904  0.411999  0.325416  0.748437  0.259061\n",
       "7      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run on train \n",
    "y_train_pred = model_6.predict(x_train)\n",
    "cfm = confusion_matrix(y_train,y_train_pred)\n",
    "accuracy_training = accuracy_score(y_train,y_train_pred)\n",
    "\n",
    "# run on test data \n",
    "y_test_pred = model_6.predict(x_test)\n",
    "cfm = confusion_matrix(y_test,y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "accuracy_testing = accuracy_score(y_test,y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc = roc_auc_score(y_test, model_6.decision_function(x_test))\n",
    "ap = average_precision_score(y_test, model_6.decision_function(x_test))\n",
    "\n",
    "print(\"Confusion Matrix: \\n\",cfm)\n",
    "print(\"Training accuracy: \",accuracy_training)\n",
    "print(\"Testing  accuracy: \",accuracy_testing)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1-Score: \",f1)\n",
    "print(\"AUC: \",auc)\n",
    "print(\"Average Precision: \",ap)\n",
    "\n",
    "results_df.loc[6] = [accuracy_testing,precision,recall,f1,auc,ap]\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Interpreting model 6 results</h3>\n",
    "\n",
    "<p>\n",
    "    </p>\n",
    "<h4>Interpretation</h4>\n",
    "<li>Our model is not overfitted. We have a higher precision in comaprison to the the previous models -- gradient boosting seems to be the best for precision (i.e out of all the things we called positive more of them are actually positive in GD). f1, AUC, and AP roughly the same in comparison to the grid-searched RF. Recall decreased in comparison to grid-searched RF,we are identifying less good candiates of the existing good candidates. </li> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-size:xx-large\">Build Model 7</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Same parameters but up the sample weight to 5</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=8, min_samples_leaf=100,\n",
       "                           min_samples_split=100, n_estimators=400,\n",
       "                           subsample=0.6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" checked><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=8, min_samples_leaf=100,\n",
       "                           min_samples_split=100, n_estimators=400,\n",
       "                           subsample=0.6)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(max_depth=8, min_samples_leaf=100,\n",
       "                           min_samples_split=100, n_estimators=400,\n",
       "                           subsample=0.6)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#sample_weight is a vector that indicates the weight of each \n",
    "#case in the training sample\n",
    "#If you're interested, try values from 1 to 10 instead of 4\n",
    "sample_weight = np.array([5 if i == 1 else 1 for i in y_train])\n",
    "\n",
    "\n",
    "model_7 = GradientBoostingClassifier(min_samples_split=100,\n",
    "                                     max_depth=8,\n",
    "                                 min_samples_leaf=100,\n",
    "                                 n_estimators=400,\n",
    "                                 subsample=0.6)\n",
    "model_7.fit(x_train,y_train,sample_weight=sample_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[117832  32117]\n",
      " [  9158  10444]]\n",
      "Training accuracy:  0.7730071584566852\n",
      "Testing  accuracy:  0.7565629220706455\n",
      "Precision:  0.2453889711237988\n",
      "Recall:  0.5328027752270177\n",
      "F1-Score:  0.336019818863311\n",
      "AUC:  0.7479983741355032\n",
      "Average Precision:  0.2597027329087849\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.227769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.884389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692871</td>\n",
       "      <td>0.227346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.630896</td>\n",
       "      <td>0.183822</td>\n",
       "      <td>0.637384</td>\n",
       "      <td>0.285349</td>\n",
       "      <td>0.689325</td>\n",
       "      <td>0.225067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.801033</td>\n",
       "      <td>0.248407</td>\n",
       "      <td>0.355933</td>\n",
       "      <td>0.292604</td>\n",
       "      <td>0.694597</td>\n",
       "      <td>0.228761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.756876</td>\n",
       "      <td>0.239756</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>0.325777</td>\n",
       "      <td>0.727998</td>\n",
       "      <td>0.255029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.802520</td>\n",
       "      <td>0.268904</td>\n",
       "      <td>0.411999</td>\n",
       "      <td>0.325416</td>\n",
       "      <td>0.748437</td>\n",
       "      <td>0.259061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.756563</td>\n",
       "      <td>0.245389</td>\n",
       "      <td>0.532803</td>\n",
       "      <td>0.336020</td>\n",
       "      <td>0.747998</td>\n",
       "      <td>0.259703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall  f1_score       AUC        AP\n",
       "Model                                                             \n",
       "1      0.884383   0.000000  0.000000  0.000000  0.692962  0.227769\n",
       "2      0.884389   0.000000  0.000000  0.000000  0.692871  0.227346\n",
       "3      0.630896   0.183822  0.637384  0.285349  0.689325  0.225067\n",
       "4      0.801033   0.248407  0.355933  0.292604  0.694597  0.228761\n",
       "5      0.756876   0.239756  0.508060  0.325777  0.727998  0.255029\n",
       "6      0.802520   0.268904  0.411999  0.325416  0.748437  0.259061\n",
       "7      0.756563   0.245389  0.532803  0.336020  0.747998  0.259703"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run on train \n",
    "y_train_pred = model_7.predict(x_train)\n",
    "cfm = confusion_matrix(y_train,y_train_pred)\n",
    "accuracy_training = accuracy_score(y_train,y_train_pred)\n",
    "\n",
    "# run on test data \n",
    "y_test_pred = model_7.predict(x_test)\n",
    "cfm = confusion_matrix(y_test,y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "accuracy_testing = accuracy_score(y_test,y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc = roc_auc_score(y_test, model_7.decision_function(x_test))\n",
    "ap = average_precision_score(y_test, model_7.decision_function(x_test))\n",
    "\n",
    "print(\"Confusion Matrix: \\n\",cfm)\n",
    "print(\"Training accuracy: \",accuracy_training)\n",
    "print(\"Testing  accuracy: \",accuracy_testing)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1-Score: \",f1)\n",
    "print(\"AUC: \",auc)\n",
    "print(\"Average Precision: \",ap)\n",
    "\n",
    "results_df.loc[7] = [accuracy_testing,precision,recall,f1,auc,ap]\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Interpreting model 7 results</h3>\n",
    "\n",
    "<p>\n",
    "    </p>\n",
    "<h4>Interpretation</h4>\n",
    "<li>Not overfitted. This model outperforms performs (nearly) just as well if not better than all other models across all categories except recall. It's as close as we are going to get to perfect precision and recall (among the seven models) as indicated by f1 score. In other words this is the most-well rounded model as supported by the AUC score. </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;font-size:xx-large\">Model comparison</h3>\n",
    "<li>Draw a graph that shows the changes to accuracy, precision, recall, and f1 score</li>\n",
    "<li>The x-axis contains the five models you have created</li>\n",
    "<li>Use bokeh for the charts</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"ec2b6966-ab1d-4860-86b3-de8a7fb9bedb\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"ec2b6966-ab1d-4860-86b3-de8a7fb9bedb\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"ec2b6966-ab1d-4860-86b3-de8a7fb9bedb\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import ColumnDataSource, LabelSet, HoverTool\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"b7f099d1-f998-4218-ba6f-6caf22c327b5\" data-root-id=\"p1585\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"36fb7b16-3086-42ea-8468-16bbaff39878\":{\"version\":\"3.2.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1585\",\"attributes\":{\"width\":800,\"height\":350,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p1595\",\"attributes\":{\"factors\":[\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\",\"Model 7\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1587\"},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p1596\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1597\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1588\",\"attributes\":{\"text\":\"Model Metrics\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1614\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1608\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1609\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1610\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\",\"Model 7\"]],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"/lsATt1M7D9Ohx31BgDiP1kJ3zdMMOQ/9OKonxCi6T92dpr+UjjoPySrVZM9ruk/mRv1ccM16D8=\"},\"shape\":[7],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1615\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1616\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1611\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1612\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1613\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_alpha\":0.2,\"line_width\":2}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1625\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1619\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1620\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1621\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\",\"Model 7\"]],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAAB0hBRF7ArGP40ZaQJ5h8c/T8ERvMrLzz+slw8vVrDOP0Gr9fu5NdE/jU3j4udozz8=\"},\"shape\":[7],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1626\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1627\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1622\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"green\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1623\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"green\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1624\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"green\",\"line_alpha\":0.2,\"line_width\":2}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1635\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1629\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1630\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1631\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\",\"Model 7\"]],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAAB72KBiQGfnP6pkYgFzZeQ/tuq2fZvH1j9jal/jB0LgP+cT1hwwXto/ti3aZ7gM4T8=\"},\"shape\":[7],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1636\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1637\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1632\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"red\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1633\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"red\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1634\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"red\",\"line_alpha\":0.2,\"line_width\":2}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1645\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1639\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1640\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1641\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\",\"Model 7\"]],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAACS+qK9ctfRP+XhdOEnQ9I/ZANI0Qa60j/gU7Bgh9nUP5lYYqyb09Q/VNk0RVmB1T8=\"},\"shape\":[7],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1646\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1647\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1642\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"orange\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1643\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"orange\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1644\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"orange\",\"line_alpha\":0.2,\"line_width\":2}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1594\"},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1603\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1604\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1605\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1606\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p1598\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p1599\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p1600\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1601\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1602\",\"attributes\":{\"axis\":{\"id\":\"p1598\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1607\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1603\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1617\",\"attributes\":{\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1618\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Accuracy\"},\"renderers\":[{\"id\":\"p1614\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1628\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Precison\"},\"renderers\":[{\"id\":\"p1625\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1638\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Recall\"},\"renderers\":[{\"id\":\"p1635\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1648\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"f1_score\"},\"renderers\":[{\"id\":\"p1645\"}]}}]}}]}}]}};\n  const render_items = [{\"docid\":\"36fb7b16-3086-42ea-8468-16bbaff39878\",\"roots\":{\"p1585\":\"b7f099d1-f998-4218-ba6f-6caf22c327b5\"},\"root_ids\":[\"p1585\"]}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1585"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CHART \n",
    "models = ['Model 1','Model 2','Model 3','Model 4','Model 5','Model 6','Model 7']\n",
    "p = figure(\n",
    "    x_range=models, \n",
    "    height = 350, \n",
    "    width = 800,\n",
    "    title = 'Model Metrics', \n",
    "    toolbar_location = None, \n",
    "    tools = \"\"\n",
    "    )\n",
    "\n",
    "p.line(models, results_df['accuracy'], line_width = 2, legend_label = 'Accuracy', line_color = 'blue')\n",
    "p.line(models, results_df['precision'], line_width = 2, legend_label = 'Precison', line_color = 'green')\n",
    "p.line(models, results_df['recall'], line_width = 2, legend_label = 'Recall', line_color = 'red')\n",
    "p.line(models, results_df['f1_score'], line_width = 2, legend_label = 'f1_score', line_color = 'orange')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Interpret the chart</h3>\n",
    "<li>What can you say about the changes in precision and recall</li>\n",
    "Precision: for hte most part increases steadily as we iteterate over the models\n",
    "Recall: oscillates between increasing and decreasing states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Chart AUC and AP</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"f38f4428-1c52-4150-885d-7c9b5ce106f6\" data-root-id=\"p1653\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"f1f5ba3d-f684-4749-b995-7b2c6e8232eb\":{\"version\":\"3.2.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1653\",\"attributes\":{\"width\":800,\"height\":350,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p1663\",\"attributes\":{\"factors\":[\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\",\"Model 7\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1655\"},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p1664\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1665\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1656\",\"attributes\":{\"text\":\"AUC and AP\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1682\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1676\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1677\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1678\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\",\"Model 7\"]],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"aUw/BL8s5j98FlayUjXmPztrOLzyDuY/ETur3iI65j+I6tzXwUvnP1DZdNcy8+c/6vBLSZrv5z8=\"},\"shape\":[7],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1683\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1684\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1679\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1680\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1681\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_alpha\":0.2,\"line_width\":2}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1693\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1687\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1688\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1689\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\",\"Model 7\"]],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"2hlIYIonzT82xF6lSGzNPwmRreb9zsw/JOo2DApIzT8+a2J7ZFLQP+qWFK51lNA/fJohNvie0D8=\"},\"shape\":[7],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1694\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1695\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1690\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1691\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1692\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_alpha\":0.2,\"line_width\":2}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1662\"},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1671\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1672\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1673\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1674\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p1666\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p1667\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p1668\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1669\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1670\",\"attributes\":{\"axis\":{\"id\":\"p1666\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1675\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1671\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1685\",\"attributes\":{\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1686\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"AUC\"},\"renderers\":[{\"id\":\"p1682\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1696\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"AP\"},\"renderers\":[{\"id\":\"p1693\"}]}}]}}]}}]}};\n  const render_items = [{\"docid\":\"f1f5ba3d-f684-4749-b995-7b2c6e8232eb\",\"roots\":{\"p1653\":\"f38f4428-1c52-4150-885d-7c9b5ce106f6\"},\"root_ids\":[\"p1653\"]}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1653"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CHART\n",
    "p = figure(\n",
    "    x_range=models, \n",
    "    height = 350, \n",
    "    width = 800, \n",
    "    title = 'AUC and AP', \n",
    "    toolbar_location = None, \n",
    "    tools = \"\"\n",
    "    )\n",
    "p.line(models, results_df['AUC'], line_width = 2, legend_label = 'AUC', line_color = 'black')\n",
    "p.line(models, results_df['AP'], line_width = 2, legend_label = 'AP', line_color = 'blue')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Interpret the AUC/AP chart</h3>\n",
    "<li>The AUC on the first 4 models is pretty much the same. What does that mean?</li>\n",
    "<ul><li>Conceptually this tells us that The models are not getting any better (i.e are not gaining any useful information) at distinguishing positive from negative cases. Practically this is telling us that that no model is better than another. We know this is the case because AUC is primarily used as a way to compare models, where the best models will have the highest AUC.   </li>\n",
    "    </ul>\n",
    "<li>The average precision improves steadily but almost entirely by getting better at recall than at precision. What does that mean?</li>\n",
    "    \n",
    "<li>AP is weighted mean of precisions at each threshold. Here the weight is the increase in recall from the prior threshold. If our AP is steadily increasing from model to model then our change in recall (as a function of threshold) is more drastic (larger) from model to model. This tells us that our recall is getting more sensitive to changes in threshold from model to model. </li>\n",
    "\n",
    "<li>Finally, what can you do to get better results? </li>\n",
    "<ul>\n",
    "    <li>Get more context on the problem to better specify a larger set of hyper paramters and thereby improve the performance of our model. In this assignment we only used a small subset of hyperparamters to tune our models. We could include more though this will increase the runtime. If we understood which hyperparamters are most relevant/helpful to classify our data then we can use gridsearch more efficiently. Ideally this continued hyperparameter tuning will allow us to imrpove our AUC and f1 scores. </li></ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "    - reflecting on the threshold in the loss function: the threshols sets the tolerable prediciton error, the threshold. If we ever exceed this threshold then it can be thought of rejecting the null in hypothesis testing. Because our data gives us reason to beleive that we have an instance of an 'extreme' data point we reject the null, that our data point is a negative, and accept the alternative hypothesis, that we have a positive. \n",
    "        - following this line of logic I think that the predcition error is our computed t-statistic, and our threshold is the alpha, the amount of type1 errors we tolerate; us varying the threshold is us computing the p-value --> is the \n",
    "        - increasing threshold tells us we need alot of evidence to say something is positive\n",
    "    - I'm struggling to differentiate AUC from accuracy. So far I think that AUC as the accuracy of a model at a given threshold. \n",
    "    - how exactly do we make the algo favor positive cases by giving them higher weight\n",
    "    - what does it mean to be a linear classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

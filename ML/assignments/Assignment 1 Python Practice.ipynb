{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Problem 1: Word counts</h1>\n",
    "Write a function <span style=\"color:red\">word_count</span> that takes a text string as an argument and returns a dictionary containing the count of words in that string\n",
    "\n",
    "For example: \n",
    "\n",
    "For the  string \"It was the best of times it was the worst of times\", your function should return the following dictionary:\n",
    "\n",
    "{'It': 1,\n",
    " 'best': 1,\n",
    " 'it': 1,\n",
    " 'of': 2,\n",
    " 'the': 2,\n",
    " 'times': 2,\n",
    " 'was': 2,\n",
    " 'worst': 1}\n",
    " \n",
    " Notes:\n",
    " \n",
    " 1. Assume that there is no punctuation, not even the end of sentence period, in the string, only words separated by spaces. \n",
    " \n",
    " 2. The function <span style=\"color:red\">split</span> splits a string on spaces. An example call of the function is: <span style=\"color:red\">\"hello fellow\".split()</span> which will return the list <span style=\"color:red\">['hello', 'fellow']</span>\n",
    " \n",
    " 3. Treat words with different cases as different words (\"hello\" and \"Hello\" are not the same word)\n",
    " \n",
    " 4. You might find the <a href=\"http://book.pythontips.com/en/latest/for_-_else.html\">for ... else ...</a> structure useful for this problem \n",
    " \n",
    " 5. If the string is empty, the function should return an empty dictionary\n",
    " \n",
    " 6. Depending on your version of python, the ordering of words in your dictionary may be different from what is in my dictionary. The count matters, not the order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    '''\n",
    "    goal: return a dictionary with keys as distinct words in the text and values as the number of appearances\n",
    "          of that word\n",
    "    \n",
    "    questions \n",
    "    - how do we isolate each word\n",
    "        use the split function and then add NEW words to dictionary, increase count when old\n",
    "    \n",
    "    efficiency \n",
    "    time complexity: o(n^2) searching dictionary in for loop is o(n)\n",
    "    space complexity: o(n) for dict and n for the words list; n is the number of words\n",
    "    '''\n",
    "    counts = dict()\n",
    "\n",
    "    #Your code goes here\n",
    "    \n",
    "    # use split to get each individual word \n",
    "    words = text.split()\n",
    "    \n",
    "    # catch the null case \n",
    "    if len(words) == 0: return counts\n",
    "    \n",
    "    for word in words: \n",
    "        if word in counts:\n",
    "            counts[word]+=1\n",
    "        else:\n",
    "            counts[word]=1\n",
    "    \n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'It': 1, 'was': 2, 'the': 2, 'best': 1, 'of': 2, 'times': 2, 'it': 1, 'worst': 1}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "#test your function with the following sample data\n",
    "\n",
    "#Should return {'It': 1, 'best': 1, 'it': 1, 'of': 2, 'the': 2, 'times': 2, 'was': 2, 'worst': 1}\n",
    "text1 = \"It was the best of times it was the worst of times\"\n",
    "print(word_count(text1))\n",
    "\n",
    "#Should return {}\n",
    "text1 = \"\"\n",
    "print(word_count(text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Problem 2: word encodings and vocabulary</h1>\n",
    "Many text mining problems use word encodings as an input to the analytic process. The idea behind word encodings is very simple: a corpus of documents (corpus = \"many documents\" in simple English!) contains a vocabulary (the set of words used across all documents). The vocabulary is textual (\"green\", \"people\", \"carrots\") but data analysis needs  numerical data. The solution is to replace each word with a numeric code. For example, if the corpus contains two documents:\n",
    "\n",
    "doc1 = \"it was the best of times it was the worst of times\"<br>\n",
    "doc2 = \"The good times of today are the sad thoughts of tomorrow\"\n",
    "\n",
    "Then we can represent word encodings by the following dictionary (note that your numbering may be different):\n",
    "\n",
    "{'are': 9,\n",
    " 'best': 3,\n",
    " 'good': 7,\n",
    " 'it': 0,\n",
    " 'of': 4,\n",
    " 'sad': 10,\n",
    " 'the': 2,\n",
    " 'thoughts': 11,\n",
    " 'times': 5,\n",
    " 'today': 8,\n",
    " 'tomorrow': 12,\n",
    " 'was': 1,\n",
    " 'worst': 6}\n",
    " \n",
    " If you look at the dictionary carefully, the encoding process should be very clear. \"it\" was the first word in the first document and it was encoded as a 0. \"was\" was the second word and it was encoded as a 1. And so on. Each distinct word is associated with an integer and the size of the vocabulary is the number of distinct words.\n",
    " \n",
    " Write a function <span style=\"color:blue\">vocabulary</span> that takes a list of documents as an argument and returns a dictionary containing the encoded vocabulary\n",
    " \n",
    " Notes:\n",
    " \n",
    " 1. Assume that each document is a single text string containing words separated by spaces and with absolutely no punctuation (not even periods at the end)\n",
    "\n",
    "2. If the corpus is empty, the function should return an empty dictionary\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary(corpus):\n",
    "    '''\n",
    "    goal: make a dictionary where the keys are distinct words and the values are the IDs associated with each word;\n",
    "    start your IDs such that your first word has ID 0 and your second has ID 1 (if it is a new word); return \n",
    "    the dictionary after probing both documents\n",
    "    \n",
    "    questions \n",
    "    - method add words to dictionary \n",
    "        + linearly probe the 1st document, check if the word is in the dictionary if not add it\n",
    "        + need to keep track of a cntr that will allow us to make new IDs according to the number of new words\n",
    "        \n",
    "    efficiency: \n",
    "    time: o(m*n^2) where m is the number of docs and n is the avg number of words in docs\n",
    "    space: o(n) where n scales with the number of distinct words in across documents\n",
    "    '''\n",
    "    vocab = dict()\n",
    "    \n",
    "    #YOUR CODE GOES HERE\n",
    "    \n",
    "    # check for the null case:\n",
    "    if len(corpus) == 0: return vocab\n",
    "    \n",
    "    ID = 0\n",
    "    # loop over our documents\n",
    "    for document in corpus:\n",
    "        \n",
    "        words_in_doc = document.split()\n",
    "        for word in words_in_doc:\n",
    "            if word in vocab:\n",
    "                pass\n",
    "            else:\n",
    "                vocab[word] = ID\n",
    "                ID+=1\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'it': 0, 'was': 1, 'the': 2, 'best': 3, 'of': 4, 'times': 5, 'worst': 6, 'good': 7, 'today': 8, 'are': 9, 'sad': 10, 'thoughts': 11, 'tomorrow': 12}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "#Test your function with the following example. \n",
    "#Should return: \n",
    "{'it': 0,'was': 1,'the': 2,'best': 3,'of': 4,'times': 5,'worst': 6,'good': 7,'today': 8,'are': 9,'sad': 10,'thoughts': 11,'tomorrow': 12}#\n",
    "doc1 = \"it was the best of times it was the worst of times\"\n",
    "doc2 = \"the good times of today are the sad thoughts of tomorrow\"\n",
    "\n",
    "print(vocabulary([doc1,doc2]))\n",
    "\n",
    "doc1 = \"\"\n",
    "doc2 = \"\"\n",
    "print(vocabulary([doc1,doc2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Problem 3: word_vectors</h1>\n",
    "The  <span style=\"color:red\">vocabulary</span> function returns a dictionary containing the word encoded vocabulary associated with the corpus. Once the encoding is done, each document can be replaced by a <span style=\"color:blue\">word vector</span> that indicates which words (from the vocabulary) are present in the document and with what frequency. For example, given the corpus:\n",
    "\n",
    "doc1 = \"it was the best of times it was the worst of times\"\n",
    "\n",
    "doc2 = \"The good times of today are the sad thoughts of tomorrow\"\n",
    "\n",
    "the word vector corresponding to doc1 is:\n",
    "\n",
    "[2, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "Note that the length of the vector is equal to the length of the entire vocabulary. Each location in the word vector corresponds to the code for the corresponding word in the vocabulary. The value at each location is the frequency of the eord in the document. Thus, location 0 corresponds to the word \"it\" which occurs twice in the doc1. Location 3 corresponds to \"best\" which occurs once in doc1. \n",
    "\n",
    "Write a function <span style=\"color:red\">word_vectors</span> that takes a list of texts as an argument and returns a list of word vectors. \n",
    "\n",
    "Notes:\n",
    "\n",
    "1. Use the word_count function to get word frequencies\n",
    "\n",
    "2. Use the vocabulary function to get the encoded vocabulary for the corpus\n",
    "\n",
    "3. You can construct a list of zeros of a given length using <span style=\"color:blue\">[0]*n</span> where n is an integer. <span style=\"color:blue\">[0] * len(vocabulary)</span> will return a list of zeros of the length of the vocabulary. Create this list for each document and update individual locations by their corresponding frequencies in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vectors(corpus):\n",
    "    '''\n",
    "    goal: create a word vector for each document\n",
    "    \n",
    "    questions\n",
    "    - what is a word vector:\n",
    "        a word vector is a list where each element in the list maps a words location to its frequency;\n",
    "        for example position one in the word vector maps to the second word in the document and is valued the number \n",
    "        of time the word appears in the document\n",
    "        \n",
    "    - how do we want to efficiently construct the word vector\n",
    "        + loop over the documents \n",
    "        + make a freq dict \n",
    "        + make a vector of size n, where n is the total number of words across all documents\n",
    "        + loop over the split text in the CURRENT document mapping the word to a index and a freq and update \n",
    "        the vector \n",
    "        '''\n",
    "    vocab = vocabulary(corpus)\n",
    "    word_vectors = list()\n",
    "\n",
    "    #YOUR CODE GOES HERE\n",
    "    \n",
    "    # check the null case:\n",
    "    if len(corpus) == 0: return word_vectors\n",
    "    \n",
    "    for document in corpus:\n",
    "        # create the word vector\n",
    "        curr_word_vector = [0]*len(vocab)\n",
    "        # get the frequencies \n",
    "        freqs = word_count(document)\n",
    "        # loop over all of the words in the document\n",
    "        for word in freqs:\n",
    "            # update the word vector\n",
    "            idx_word = vocab[word]\n",
    "            freq_word = freqs[word]\n",
    "            curr_word_vector[idx_word] = freq_word\n",
    "            \n",
    "        # add the word vector to the result\n",
    "        word_vectors.append(curr_word_vector)\n",
    "        \n",
    "    return word_vectors\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The function should return two lists:\n",
    "[[2, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0],\n",
    " [0, 0, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1]]\n",
    "\"\"\"\n",
    "doc1 = \"it was the best of times it was the worst of times\"\n",
    "doc2 = \"the good times of today are the sad thoughts of tomorrow\"\n",
    "word_vectors([doc1,doc2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Problem 4: Moving averages</h1>\n",
    "Moving averages are often used in trend analysis in timeseries data. A simple way of figuring out whether a timeseries is trending (i.e., moving consistently in either the upward or downward direction) or mean reverting (i.e., fluctuating around a mean) is to see if a shorter term moving average is consistently below or above a longer term moving average. \n",
    "\n",
    "Write a function <span style=\"color:blue\">getMovingAverage(series,duration)</span> that takes a list of numbers as an input (the series) and returns a n-period (the duration) moving average series of the same length as the original list. For each k-th element in the first n-1 elements, return the average of the k elemets.\n",
    "\n",
    "For example, if:\n",
    "\n",
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "and\n",
    "\n",
    "duration = 4\n",
    "\n",
    "then, getMovingAverage(x,duration) should return:\n",
    "\n",
    "[1.0, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]\n",
    "\n",
    "The average at k=0 is 1/1<br>\n",
    "The average at k=1 is (1 + 2)/2<br>\n",
    "The average at k=2 is (1 + 2 + 3)/3<br>\n",
    "The average at k=3 is (1 + 2 + 3 + 4)/4<br>\n",
    "The average at k=4 is (2 + 3 + 4 + 5)/4<br>\n",
    "etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getMovingAverage(series,duration):\n",
    "    '''\n",
    "    goal: get the moving average over a maximum history of length duration\n",
    "    \n",
    "    questions\n",
    "    how does the duration affect the average\n",
    "    - we must take the average of no more than duration consecutive numbers \n",
    "    \n",
    "    how do we want to efficiently do this problem \n",
    "    - we employ a sliding window approach \n",
    "    - keep taking the averages of numbers between left and right idxs so long as right - left <= duration \n",
    "    - once this inequality is no longer true we need to increase left until it holds true\n",
    "    '''\n",
    "    mvg_avg = list()\n",
    "    running_sum = 0\n",
    "\n",
    "    #YOUR CODE GOES HERE\n",
    "    \n",
    "    # null case \n",
    "    if len(series) == 0: return mvg_avg\n",
    "    \n",
    "    left, right = 0,0 \n",
    "    while right < len(series):\n",
    "        \n",
    "        if right - left+1 <= duration:\n",
    "            # take the average \n",
    "            avg = sum(series[left:right+1])/(right-left+1)\n",
    "            mvg_avg.append(avg)\n",
    "            \n",
    "            # update ptr\n",
    "            right+=1\n",
    "        else:\n",
    "            # if our window is too large then we need to shrink until we are within the range of duration \n",
    "            left+=1 \n",
    "    return mvg_avg\n",
    "    \n",
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "getMovingAverage(x,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
      "[1.0, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]\n",
      "[]\n",
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "series = [1,2,3,4,5,6,7,8,9,10]\n",
    "print(getMovingAverage(series,2)) #[1.0, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
    "print(getMovingAverage(series,4)) #[1.0, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]\n",
    "print(getMovingAverage([],4)) #[] (empty list)\n",
    "print(getMovingAverage([1],7)) #[1.0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
